# Reuters Newswire Classification with a Neural Network

This project aims to build and train a deep learning model capable of classifying newswires from the Reuters agency into 46 distinct topics. The model is a Deep Neural Network (DNN) implemented with TensorFlow and Keras.

## Table of Contents
1. [Project Description](#project-description)
2. [Dataset](#dataset)
3. [Code Structure](#code-structure)
4. [How to Run the Code](#how-to-run-the-code)
5. [Results](#results)
6. [Dependencies](#dependencies)

---

### Project Description

The objective is to tackle a multi-class text classification problem. Each newswire must be assigned to a single category out of 46 possible options. To achieve this, the project follows the classic steps of a machine learning pipeline:
- **Data Loading and Exploration** to understand its distribution.
- **Text Preprocessing** to convert it into a numerical format that the model can understand (vectorization).
- **Building a Neural Network Model**.
- **Training the Model** with techniques to prevent overfitting (`EarlyStopping`).
- **Evaluating the Model's Performance** on unseen data and comparing it to a baseline.

### Dataset

The project uses the **Reuters** dataset, which is built into Keras. It consists of 11,228 newswires for training and testing.

- **Vocabulary**: Limited to the 10,000 most frequent words.
- **Classes**: 46 different topics.
- **Distribution**: The dataset is imbalanced, with some topics being much more frequent than others, as shown in the initial visualization.

### Code Structure

The Python script is organized as follows:
1.  **Importing Libraries**: `numpy`, `matplotlib`, and `tensorflow.keras`.
2.  **Loading Data**: The Reuters dataset is loaded from `keras.datasets`.
3.  **Exploratory Data Analysis**: A visualization of the frequency of each class is generated.
4.  **Data Preprocessing**:
    - Word index sequences are converted into binary vectors of size 10,000 (a *bag-of-words* technique).
    - Class labels are transformed via one-hot encoding.
5.  **Model Creation**:
    - A `Sequential` model is defined with three `Dense` layers.
    - `relu` activation functions are used for the hidden layers, and `softmax` for the output layer (suitable for multi-class classification).
6.  **Compilation and Training**:
    - The `adam` optimizer and `categorical_crossentropy` loss function are used.
    - An `EarlyStopping` callback is configured to stop training if the validation loss does not improve for 4 consecutive epochs.
7.  **Evaluation and Visualization**:
    - The model is evaluated on the test set.
    - The training and validation loss and accuracy curves are plotted to analyze the model's behavior.
    - The model's accuracy is compared to that of a random classifier to prove its effectiveness.

### How to Run the Code

1.  Ensure you have installed all the necessary dependencies.
2.  Run the Python script. The script will automatically download the data, train the model, and display the performance graphs and final accuracy.

    ```bash
    python your_script_name.py
    ```
   
### Results

The model achieves an accuracy significantly higher than random classification, demonstrating its ability to learn relevant patterns in the text data. The loss and accuracy plots show that the training is stable and that `EarlyStopping` effectively prevents overfitting.

### Dependencies

To run this project, you will need the following Python libraries:
- `tensorflow`
- `numpy`
- `matplotlib`

You can install them via pip:
```bash
pip install tensorflow numpy matplotlib
```
